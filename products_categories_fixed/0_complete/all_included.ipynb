{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomce\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from cables_and_dividers_communicator import generate_sql_query_cable_and_divider_anthropic,generate_sql_query_cable_and_divider_google, generate_sql_query_cable_and_divider_mistral\n",
    "from gaming_laptop_communicator import generate_sql_query_gaming_laptop_anthropic,generate_sql_query_gaming_laptop_google, generate_sql_query_gaming_laptop_mistral\n",
    "from laptop_communicator import generate_sql_query_laptop_anthropic,generate_sql_query_laptop_google, generate_sql_query_laptop_mistral\n",
    "from mobile_phone_communicator import generate_sql_query_mobile_phone_anthropic,generate_sql_query_mobile_phone_google, generate_sql_query_mobile_phone_mistral\n",
    "from monitors_communicator import generate_sql_query_monitor_anthropic,generate_sql_query_monitor_google, generate_sql_query_monitor_mistral\n",
    "from mouses_communicator import generate_sql_query_mouse_anthropic,generate_sql_query_mouse_google, generate_sql_query_mouse_mistral\n",
    "from tvs_communicator import generate_sql_query_tv_anthropic,generate_sql_query_tv_google, generate_sql_query_tv_mistral\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up zero-shot classificator pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tomce\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(model=\"facebook/bart-large-mnli\")\n",
    "possible_labels = [\"cables and dividers\", \"gaming laptops\", \"laptop\", \"mouses\", \"tvs\", \"monitors\", \"mobile phones\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-shot classifier Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: What phones are there?\n",
      "Predicted Class: mobile phones\n",
      "Confidence Score: 0.8313082456588745\n",
      "{'sequence': 'What phones are there?', 'labels': ['mobile phones', 'mouses', 'cables and dividers', 'monitors', 'laptop', 'tvs', 'gaming laptops'], 'scores': [0.8313082456588745, 0.03666427731513977, 0.03313170373439789, 0.029806964099407196, 0.02954372577369213, 0.024152150377631187, 0.015392889268696308]}\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What phones are there?\"\n",
    "possible_labels = [\"cables and dividers\", \"gaming laptops\", \"laptop\", \"mouses\", \"tvs\", \"monitors\", \"mobile phones\"]\n",
    "\n",
    "# Perform zero-shot classification\n",
    "result = pipe(input_text, possible_labels)\n",
    "\n",
    "# Print the result\n",
    "print(\"Input Text:\", input_text)\n",
    "print(\"Predicted Class:\", result[\"labels\"][0])\n",
    "print(\"Confidence Score:\", result[\"scores\"][0])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Translator MKD to ENG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lang = \"eng_Latn\"\n",
    "source_lang = \"mkd_Cyrl\"\n",
    "translator = pipeline('translation', model=model, tokenizer=tokenizer, src_lang=source_lang, tgt_lang=target_lang, max_length = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What gaming laptop has at least 8GB of RAM?\n"
     ]
    }
   ],
   "source": [
    "text = \"Што гејминг лаптопи има со барем 8гб рам?\"\n",
    "output = translator(text)\n",
    "translated_text = output[0]['translation_text']\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: What gaming laptop has at least 8GB of RAM?\n",
      "Predicted Class: gaming laptops\n",
      "Confidence Score: 0.6107091903686523\n"
     ]
    }
   ],
   "source": [
    "result2= pipe(translated_text, possible_labels)\n",
    "print(\"Input Text:\", translated_text)\n",
    "print(\"Predicted Class:\", result2[\"labels\"][0])\n",
    "print(\"Confidence Score:\", result2[\"scores\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract query off API output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sql_query(text):\n",
    "    # Define the regular expression pattern for the SQL query\n",
    "    pattern = re.compile(r'```(?:sql)?\\n(.*?)\\n```', re.DOTALL)\n",
    "    \n",
    "    # Search for the pattern in the input text\n",
    "    match = pattern.search(text)\n",
    "    \n",
    "    # If a match is found, return the query, otherwise return None\n",
    "    return match.group(1) if match else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete SQL Query Generator With Translator and Zero-Shot Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What gaming laptops have at least 8GB of RAM and have OLED displays?\n",
      "gaming laptops\n",
      "SELECT gl.title\n",
      "FROM gaming_laptops gl\n",
      "JOIN gaming_laptop_feature glf ON gl.id = glf.product_id\n",
      "JOIN feature_gaming_laptops fgl ON glf.feature_id = fgl.id\n",
      "WHERE fgl.feature_name = 'ram_size_gb' AND fgl.feature_value >= '8'\n",
      "  AND gl.id IN (\n",
      "    SELECT glf.product_id\n",
      "    FROM gaming_laptop_feature glf\n",
      "    JOIN feature_gaming_laptops fgl ON glf.feature_id = fgl.id\n",
      "    WHERE fgl.feature_name LIKE '%screen_type%' AND fgl.feature_value LIKE '%OLED%'\n",
      "  );\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Што гејминг лаптопи има со барем 8гб РАМ меморија и имаат екран со OLED дисплеј?\"\n",
    "user_question_translated = translator(user_question)[0]['translation_text']\n",
    "user_question_category= pipe(user_question_translated, possible_labels)[\"labels\"][0]\n",
    "print(user_question_translated)\n",
    "print(user_question_category)\n",
    "if(user_question_category == \"cables and dividers\"):\n",
    "    sql_query = extract_sql_query(generate_sql_query_cable_and_divider_mistral(user_question_translated))\n",
    "elif(user_question_category == \"gaming laptops\"):\n",
    "    sql_query = extract_sql_query(generate_sql_query_gaming_laptop_anthropic(user_question_translated))\n",
    "elif(user_question_category == \"laptop\"):\n",
    "    sql_query = extract_sql_query(generate_sql_query_laptop_mistral(user_question_translated))\n",
    "elif(user_question_category == \"mouses\"):\n",
    "    sql_query = extract_sql_query(generate_sql_query_mouse_mistral(user_question_translated))\n",
    "elif(user_question_category == \"tvs\"):\n",
    "    sql_query = extract_sql_query(generate_sql_query_tv_mistral(user_question_translated))\n",
    "elif(user_question_category == \"monitors\"):\n",
    "    sql_query = extract_sql_query(generate_sql_query_monitor_mistral(user_question_translated))\n",
    "elif(user_question_category == \"mobile phones\"):\n",
    "    sql_query = extract_sql_query(generate_sql_query_mobile_phone_mistral(user_question_translated))\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\tomce\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "testing = generate_sql_query_cable_and_divider_mistral(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT cables_and_dividers.title, cable_length_meters.feature_value, number_of_sockets.feature_value\n",
      "FROM cables_and_dividers\n",
      "JOIN cable_and_divider_feature AS cable_feature1 ON cables_and_dividers.id = cable_feature1.product_id\n",
      "JOIN feature_cables_and_dividers AS cable_length_meters ON cable_feature1.feature_id = cable_length_meters.id\n",
      "JOIN cable_and_divider_feature AS cable_feature2 ON cables_and_dividers.id = cable_feature2.product_id\n",
      "JOIN feature_cables_and_dividers AS number_of_sockets ON cable_feature2.feature_id = number_of_sockets.id\n",
      "WHERE cable_length_meters.feature_name = 'cable_length_meters'\n",
      "AND CAST(cable_length_meters.feature_value AS INTEGER) >= 3\n",
      "AND number_of_sockets.feature_name = 'number_of_sockets'\n",
      "AND CAST(number_of_sockets.feature_value AS INTEGER) >= 3;\n"
     ]
    }
   ],
   "source": [
    "print(extract_sql_query(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing2 = generate_sql_query_tv_anthropic(\"What are the TVs that are 4k and have a screen size of 50 inches or more?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the TVs that are 4K and have a screen size of 50 inches or more, we can use the following SQL query:\n",
      "\n",
      "```sql\n",
      "SELECT tvs.title, screen_size.feature_value AS screen_size_inches, screen_resolution.feature_value AS screen_resolution\n",
      "FROM tvs\n",
      "JOIN tv_feature AS tvf1 ON tvs.id = tvf1.product_id\n",
      "JOIN feature_tvs AS screen_size ON tvf1.feature_id = screen_size.id AND screen_size.feature_name = 'screen_size_inches'\n",
      "JOIN tv_feature AS tvf2 ON tvs.id = tvf2.product_id\n",
      "JOIN feature_tvs AS screen_resolution ON tvf2.feature_id = screen_resolution.id AND screen_resolution.feature_name = 'screen_resolution'\n",
      "WHERE CAST(screen_size.feature_value AS INTEGER) >= 50\n",
      "AND screen_resolution.feature_value LIKE '%1920 x 1080%' OR screen_resolution.feature_value LIKE '%3840 x 2160%';\n",
      "```\n",
      "\n",
      "Here's a breakdown of the query:\n",
      "\n",
      "1. We join the `tvs` table with the `tv_feature` and `feature_tvs` tables to retrieve the TV title, screen size, and screen resolution.\n",
      "2. The `JOIN` clauses connect the tables based on the foreign key relationships.\n",
      "3. The `WHERE` clause filters the results to include only TVs with a screen size of 50 inches or more (`CAST(screen_size.feature_value AS INTEGER) >= 50`).\n",
      "4. The `WHERE` clause also filters the results to include only TVs with a screen resolution of either 1920 x 1080 (Full HD) or 3840 x 2160 (4K) using the `LIKE` operator and wildcard `%` for text matching.\n",
      "\n",
      "This query will return the TV title, screen size in inches, and screen resolution for all TVs that meet the criteria of being 4K (1920 x 1080 or 3840 x 2160 resolution) and having a screen size of 50 inches or larger.\n"
     ]
    }
   ],
   "source": [
    "print(testing2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT tvs.title, screen_size.feature_value AS screen_size_inches, screen_resolution.feature_value AS screen_resolution\n",
      "FROM tvs\n",
      "JOIN tv_feature AS tvf1 ON tvs.id = tvf1.product_id\n",
      "JOIN feature_tvs AS screen_size ON tvf1.feature_id = screen_size.id AND screen_size.feature_name = 'screen_size_inches'\n",
      "JOIN tv_feature AS tvf2 ON tvs.id = tvf2.product_id\n",
      "JOIN feature_tvs AS screen_resolution ON tvf2.feature_id = screen_resolution.id AND screen_resolution.feature_name = 'screen_resolution'\n",
      "WHERE CAST(screen_size.feature_value AS INTEGER) >= 50\n",
      "AND screen_resolution.feature_value LIKE '%1920 x 1080%' OR screen_resolution.feature_value LIKE '%3840 x 2160%';\n"
     ]
    }
   ],
   "source": [
    "print(extract_sql_query(testing2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "# {schema}\n",
    "\n",
    "# Question: {question}\n",
    "# SQL Query: {query}\n",
    "# SQL Response: {response}\"\"\"\n",
    "# prompt_response = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# def run_query(query):\n",
    "#     return input_db.run(query)\n",
    "\n",
    "# full_chain = (\n",
    "#     RunnablePassthrough.assign(query=sql_chain).assign(\n",
    "#         schema=get_schema,\n",
    "#         response=lambda vars: run_query(vars[\"query\"]),\n",
    "#     )\n",
    "#     | prompt_response\n",
    "#     | llm\n",
    "# )\n",
    "# print(full_chain.invoke({\"question\": user_question}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
