{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomce\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    ")\n",
    "from typing import List, Optional\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from json import JSONDecodeError\n",
    "import sys\n",
    "import stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load up Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Initialize LangChain model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", token=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read up Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_dir = r\"C:\\Users\\tomce\\OneDrive - UKIM, FINKI\\Desktop\\Fakultet 3ta Godina\\2 Sesti Semestar\\0 DATA SCIENCE SEMINARSKA\\1 Starting Over\\products_categories_fixed\\mouses\\templates\\template.txt\"\n",
    "\n",
    "os.chmod(pat_dir, stat.S_IREAD | stat.S_IWRITE)\n",
    "\n",
    "with open(pat_dir, \"r\") as f: template = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"\n",
    "{\n",
    "    \"url\": \"https://www.neptun.mk/categories/GLUVCINA/EVEREST-SM-258-Usb-1200dpi-Red--34582-\",\n",
    "    \"title\": \"MOUSE EVEREST SM-258 USB 1200DPI RED (34582)\",\n",
    "    \"warranty\": \"24\",\n",
    "    \"regular_price\": \"219\",\n",
    "    \"happy_price\": \"105\",\n",
    "    \"description\": [\n",
    "        \"Mouse\\nUsb конекција\\n1200dpi\\nОптички\\nБрој на копчиња:3\\nДолжина на кабелот:110Cm\"\n",
    "    ],\n",
    "    \"category\": \"GLUVCINA\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Prompt Template for Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "{{tmplate}}\n",
    "\n",
    "You need to extract the features of the provided product:\n",
    "{{text}}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"template\",\"text\"], template_format=\"jinja2\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Feature Extraction for Single Product Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"url\": \"https://www.neptun.mk/categories/GLUVCINA/EVEREST-SM-258-Usb-1200dpi-Red--34582-\",\n",
      "    \"title\": \"MOUSE EVEREST SM-258 USB 1200DPI RED (34582)\",\n",
      "    \"warranty_months\": 24,\n",
      "    \"regular_price_mkd\": 219,\n",
      "    \"happy_price_mkd\": 105,\n",
      "    \"category\": \"GLUVCINA\",\n",
      "    \"description\": \"Mouse\\nUsb конекција\\n1200dpi\\nОптички\\nБрој на копчиња:3\\nДолжина на кабелот:110Cm\",\n",
      "    \"features\":{\n",
      "        \"device_type\": \"Mouse\",\n",
      "        \"connection_type\": \"Usb конекција\",\n",
      "        \"dpi\": 1200,\n",
      "        \"tracking_technology\": \"Оптички\",\n",
      "        \"buttons_count\": 3,\n",
      "        \"scroll_wheel\": \"Yes\",\n",
      "        \"battery_type\": null,\n",
      "        \"ergonomic_design\": null,\n",
      "        \"compatible_os\": null\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "structured_data = chain.invoke({\"tmplate\": template, \"text\": text})\n",
    "\n",
    "print(structured_data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract All Features of All Products of Mouses Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing JSON files\n",
    "input_directory = r\"C:\\Users\\tomce\\OneDrive - UKIM, FINKI\\Desktop\\Fakultet 3ta Godina\\2 Sesti Semestar\\0 DATA SCIENCE SEMINARSKA\\1 Starting Over\\products_with_categories\\GLUVCINA\"\n",
    "# Directory to save processed JSON files\n",
    "output_directory = r\"C:\\Users\\tomce\\OneDrive - UKIM, FINKI\\Desktop\\Fakultet 3ta Godina\\2 Sesti Semestar\\0 DATA SCIENCE SEMINARSKA\\1 Starting Over\\products_categories_fixed\\mouses\\mouses_new_template\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed JSON files are saved in C:\\Users\\tomce\\OneDrive - UKIM, FINKI\\Desktop\\Fakultet 3ta Godina\\2 Sesti Semestar\\0 DATA SCIENCE SEMINARSKA\\1 Starting Over\\products_categories_fixed\\mouses\\mouses_new_template\n"
     ]
    }
   ],
   "source": [
    "# Loop through all files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.json'):\n",
    "        input_filepath = os.path.join(input_directory, filename)\n",
    "        \n",
    "        # Open and read each JSON file\n",
    "        with open(input_filepath, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            text = json.dumps(data)\n",
    "            \n",
    "            # Process the JSON data using the LangChain model\n",
    "            structured_data = chain.invoke({\"tmplate\": template, \"text\": text})\n",
    "            if 'text' in structured_data:\n",
    "                try:\n",
    "                    structured_data = json.loads(structured_data['text'])\n",
    "                except JSONDecodeError:\n",
    "                    continue\n",
    "            \n",
    "            # Determine the output file path\n",
    "            output_filename = f\"processed_{filename}\"\n",
    "            output_filepath = os.path.join(output_directory, output_filename)\n",
    "            \n",
    "            # Write the processed data to the output file\n",
    "            with open(output_filepath, 'w', encoding='utf-8') as outfile:\n",
    "                json.dump(structured_data, outfile, indent=4)\n",
    "\n",
    "print(f\"Processed JSON files are saved in {output_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
